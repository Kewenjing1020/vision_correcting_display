\subsection{Light Field Displays}
In a light field display system, a light field signal that characterizes how rays transport in a 3D virtual scene is displayed to the viewers. Viewers see these incoming light rays converged at different depths, as if emitted from objects at certain depths. Recent works ~\cite{ranieri2012multi,wetzstein2012tensor,maimone2013focus} in automultiscopic display have focused on using dual or multi-stacked LCD to realistically reproduce depth cues such as focus cue, motion parallax and binocular cues.

If we fix the focal plane at depth $\mathcal{D}$ and make the light field signal only capture a slice of the 3D virtual scene at depth $\mathcal{D}$, then the viewer with a good sight will see the 2D virtual plane in focus only when focal plane is at depth $\mathcal{D}$. Therefore, we can arbitrarily change the viewer's focal plane by properly modifying the light field signal that is put on the screen. This idea of tailored display is first introduced by Pamplona~\etal~\cite{pamplona12} to be applied to vision-correcting displays.

\subsection{Computational Vision Enhancement}

%Computational methods have been widely explored to enhance human vision, mainly in producing accurate depth cues when perceiving 3D scene geometry. Love~\etal~\cite{Love:09} uses fast switchable lens to form multiplexed image with nearly correct focus cue, and MacKenzie~\etal~\cite{mackenzie2010accommodation} introduces multiple‐-focal-‐plane display to improve vergence and accommodation conflicts. Instead of improving on producing depth cues such as vergence and accommodation, we use light field display to correct low order eye aberrations. Our vision-correcting display uses parallax barrier ~\cite{ives1903parallax}, in which a pinhole mask is placed in front of the liquid crystal display (LCD), to enhance focus ability for patients with low order eye aberration. Liu~\etal~\cite{liu2009time} creates a dynamic system that uses time-multiplexed dual-focal plane for head-mounted display, and a recent work by Itoh~\etal~\cite{Itoh:2015:VED:2735711.2735787} corrects defocus via overlaying a compensation image on the user's actual view to cancel the aberration for their head-mounted display. These methods, however, require external and moving parts. Another two vision-correction displays closely related to our work were presented by Pamplona~\etal~\cite{pamplona12} and Huang~\etal~\cite{huang14}, but both methods require a fixed viewing point, while we allow the eye to freely move within a viewing zone. A more in-depth comparison is discussed in section \ref{ss:vision-correcting-displays}.

\subsection{Vision-Correcting Displays}\label{ss:vision-correcting-displays}
Notable examples of utilizing light field displays to correct viewer’s optical aberration include works of Pamplona~\etal~\cite{pamplona12} and Huang~\etal~\cite{huang14}. Pamplona~\etal~\cite{pamplona12} introduced tailored display that uses 4D light fields to correct optical eye aberration with parallax-barrier and microlens arrays. Calculating pairs of display pixels and retinal sensors, a correction model is built to create decomposed virtual object placed on the viewer’s focal range. Following this framework, Huang~\etal~\cite{huang14} optimizes intensities of light fields with extended lateral viewing range, and shows improved reconstructed image quality on retina using a pin-hole mask.
 
These approaches, however, assume that viewer should be placed at a fixed lateral and axial position, leaving future work to incorporate eye-tracking techniques. Though Huang~\etal~\cite{huang14} provided an approach to optimize display values over multiple viewpoints, there are still challenging issues on resolving artifacts including cross-talks between two neighboring viewpoints, accurate estimation of viewer’s pupil size, and expensive computational cost to optimize over more viewpoints. In addition, Pamplona~\etal~\cite{pamplona12} provided reasonably fast algorithm for real-time system, but there are also unresolved artifacts (\ie, image jitter and screen flickering) when combined with eye-tracking techniques. In addition, bandwidth of display is not fully used, since pixel values are computed using a single viewpoint.
